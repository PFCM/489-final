\documentclass[11pt, a4paper, twoside, openright]{report}

\usepackage{multirow}

\usepackage[boxruled, noend]{algorithm2e}
\DontPrintSemicolon
\usepackage{url} % for typesetting urls
\usepackage{hyperref}
\usepackage{float}

%
%  We don't want figures to float so we define
%
\newfloat{fig}{thp}{lof}[chapter]
\floatname{fig}{Figure}

%% These are standard LaTeX definitions for the document
%%                            
\title{some kind of rnn/tensor mess}
\author{Paul Francis Cunninghame Mathews}

%% This file can be used for creating a wide range of reports
%%  across various Schools
%%
%% Set up some things, mostly for the front page, for your specific document
%
% Current options are:
% [ecs|msor|sms]          Which school you are in.
%                         (msor option retained for reproducing old data)
% [bschonscomp|mcompsci]  Which degree you are doing
%                          You can also specify any other degree by name
%                          (see below)
% [font|image]            Use a font or an image for the VUW logo
%                          The font option will only work on ECS systems
%
\usepackage[image,ecs,bschonscomp]{vuwproject}

\usepackage{microtype}
\usepackage[style=numeric, firstinits=true, url=false, isbn=false, doi=false]{biblatex}% "style=numeric" is default

\addbibresource{library.bib}

\DeclareNameAlias{default}{last-first}

\AtBeginBibliography{%
  \renewcommand*{\mkbibnamelast}[1]{\textsc{#1}}%
  %% commas between authors
  \renewcommand{\multinamedelim}{\addcomma\space}
  \renewcommand{\finalnamedelim}{\addcomma\addspace\textsc{and}\space}
}

\DefineBibliographyStrings{english}{%
 andothers = {\addcomma\addspace\textsc{et\addabbrvspace al}\adddot},
 and = {\textsc{and}}
}

\renewcommand*{\labelnamepunct}{\space\space}

\DeclareFieldFormat
  [article,inbook,incollection,inproceedings,patent,thesis,unpublished]
  {title}{#1}

\renewbibmacro{in:}{%
  \ifentrytype{article}{%
  }{%
    \printtext{\bibstring{in}\intitlepunct}%
  }%
}

\renewbibmacro*{volume+number+eid}{%
  \printfield{volume}%
  \setunit*{\addcomma\space}%
  \printfield{number}%
  \setunit{\addcomma\space}%
  \printfield{eid}}

\DeclareFieldFormat{pages}{#1}

\renewbibmacro*{publisher+location+date}{%
  \printlist{publisher}%
  \setunit*{\addcomma\space}%
  \printlist{location}%
  \setunit*{\addcomma\space}%
  \usebibmacro{date}%
  \newunit}

\usepackage{tabu}
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{mathtools}
\mathtoolsset{showonlyrefs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}

% theorem-like environments
\newtheorem{prop}{Proposition}[section]
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}[section]
\newtheorem{cor}{Corollary}[thm]

% tensor/vector/matrix commands
\renewcommand\vec{\mathbf}
\newcommand{\mat}{\mathbf}
\newcommand{\tensor}[1]{\bm{\mathcal{#1}}}
\newcommand*{\midbullet}{\raisebox{-0.25ex}{\scalebox{1.2}{$\cdot$}}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\matr}{mat}
\DeclareMathOperator{\vect}{vec}
\DeclareMathOperator*{\argmin}{arg\;min}
\newcommand{\tran}[1]{#1^{\mkern-1.5mu\mathsf{T}}}

\usepackage{hyperref}
\usepackage{soul}

\usepackage{tikz}
\usetikzlibrary{shapes, positioning}
\tikzstyle{every node}=[circle, draw, fill=black,
		   inner sep=0pt, minimum width=5pt]
\tikzset{every label/.append style={anchor=mid, inner sep=0pt}}

\usepackage{subcaption}


% You should specifiy your supervisor here with
\supervisors{Marcus Frean and David Balduzzi}
% use \supervisors if there is more than one supervisor

% Unless you've used the bschonscomp or mcompsci
%  options above use
%   \otherdegree{OTHER DEGREE OR DIPLOMA NAME}
% here to specify degree

% Comment this out if you want the date printed.
\date{}

\begin{document}

% Make the page numbering roman, until after the contents, etc.
\frontmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

Recurrent Neural Networks are a class of machine learning techniques for handling sequential
data. They have achieved great practical success but
prominent architectures are opaque and unwieldy. We reveal a \emph{tensor} structure inherent
to the most successful of these networks. 
Understanding and analysing this structure gathers valuable insights into the mechanisms
and shows a natural way of extending neural networks with multi-linear algebra and tensor
decompositions.

This allows us to propose the Tensor Gate Unit,
a novel recurrent network architecture. This architecture is designed to be simple
and modular, with only a minimum of components needed for performance.
We show empirically that this relatively simple architecture is far better at solving
a number of pathological tasks than standard approaches. We also demonstrate highly
competitive results on real-world data, making use of the explicit tensor decomposition to
manage the tradeoff between expressive power and generalisation performance.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\maketitle

\include{acknowledge}

\tableofcontents

% we want a list of the figures we defined
\listof{fig}{Figures}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% individual chapters included here
\include{introduction/introduction}
\include{background/background}
\include{tensors/tensors}
\include{newarchs/design}
\include{exps/exps}
\include{conclusion/conclusion}

%TC: ignore
\appendix
\include{appendix/appendix}
%TC:endignore

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\backmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\bibliographystyle{ieeetr}
%\bibliographystyle{acm}
%\bibliography{sample}
\printbibliography

\end{document}
